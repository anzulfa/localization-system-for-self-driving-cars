{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to dos: \n",
    "- [x] pindah ke path yg bener dan semua files pengikutnya disesuaiin (LAUNCH gimana ya) \n",
    "- [ ] numpy yg penting cuman buat arg sort ga si (cuman di fungsi ambil bag berarti?)\n",
    "- [ ] apus semua path file di folder d di awal launch - check\n",
    "- [ ] coba pengganti ! (%?) buat di py biasa\n",
    "- [ ] early stopping callback\n",
    "- [ ] plot realtime progres eror di to do (berat)\n",
    "- [x] masukin readme\n",
    "- [ ] make the parameters vars customized (berat)\n",
    "- [ ] semua yg panjang2 di main (termasuk 3 operator) jadi fungsi masing2 (class ga)\n",
    "- [x] output tuned.yaml di akhir proses loop (baik setelah akhir generasi atau callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credits to the **YOLO v4 implementation of generic algorithm for hyperparameters tuning** that serves to assist the contributors in understanding the algorithm implementation -- and the few lines here and there taken directly and sometimes almost identically from their repo sure were much appreciated!\n",
    "\n",
    "**Abel**, **Adam**, and **Gilbert**, who were much help; thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rosbag\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import math as m\n",
    "from scipy.spatial.distance import cdist\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import subprocess\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ganti yaml tiap awal generasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for changing the parameter values (YAML file is used for the params to be called from the main UKF program)\n",
    "def params_yaml(p,q,repo_path,temp=False):\n",
    "    #read\n",
    "    temp_yaml_dir = repo_path + '/config/temp.yaml'\n",
    "    with open(temp_yaml_dir) as read_temp_yaml:             \n",
    "        params = yaml.safe_load(read_temp_yaml)\n",
    "    if q is not None:\n",
    "        params['initial_estimate_covariance_P'] = p\n",
    "        params['process_noise_covariance_Q'] = q\n",
    "\n",
    "    #write and save\n",
    "    if temp: #temp\n",
    "        with open(temp_yaml_dir,'w') as write_temp_yaml:    \n",
    "            yaml.safe_dump(params, write_temp_yaml, indent=2, allow_unicode=False) #dah berhasil ni     \n",
    "    else: #best\n",
    "        best_yaml_dir = repo_path + '/config/tuned.yaml'\n",
    "        with open(best_yaml_dir,'w') as write_best_yaml:      \n",
    "            yaml.safe_dump(params, write_best_yaml, indent=2, allow_unicode=False)\n",
    "        print(\"Optimization is all done and the best params are now saved to {}\".format(best_yaml_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jalanin roslaunch berisi rosbag play, ukf dengan yaml baru untuk setiap generasi, dan rosbag record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function for launching the 3 nodes: rosbag play back, the ukf algorithm, the recording of the rosbag to a temporary rosbag file that saves the estimation from the UKF\n",
    "# the ntoebook (with !) and python (with %?) capability to run terminal command is VERY crucial in making this tuning possible in the ROS environment. It was the one thing that was going to be the make or break.\n",
    "def launch(repo_path):\n",
    "    launch_path = \"{}/launch/launch_for_ga.launch\".format(repo_path)\n",
    "    !roslaunch {launch_path}\n",
    "    \n",
    "    # is not str WKWKWKWK gimana ya bair keren dipakein pwd nya.\n",
    "    # eh kan kalo di cmd line mala lebih gampang buat ngerun file dari folder laen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jalanin rosbag import cari rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def err(est, gt, t_est, t_gt):\n",
    "    j = 1\n",
    "    sample_est = []\n",
    "    sample_gt = []\n",
    "    for i in range(1, len(t_gt)):\n",
    "        while (t_gt[i] > t_est[j]):\n",
    "            j += 1\n",
    "            \n",
    "        sample_est.append(est[j])\n",
    "        sample_gt.append(gt[i])\n",
    "    rmse=sqrt(mse(sample_gt, sample_est))\n",
    "    mae=mean_absolute_error(sample_gt, sample_est)\n",
    "    print(\"rmse: \"+str(rmse)+\"\\nmae: \"+str(mae))\n",
    "    return rmse,mae\n",
    "\n",
    "#function for loading the estimation values recorded in the temporary bag file\n",
    "def ambil_bag(repo_path):\n",
    "    bag = rosbag.Bag(repo_path + '/bag/ga_temp.bag') #bagnya perlu udah ada ga ya? kayanya ngga, soalnya dibuatin dari launch filenya\n",
    "    states_xy=[]\n",
    "    states_xy_baru=[]\n",
    "    t = []\n",
    "\n",
    "    for topic, msg, time in bag.read_messages(topics=['/ukf_states']):\n",
    "        states_xy.append([msg.x,msg.y])\n",
    "        t.append(msg.stamp.to_sec())\n",
    "    \n",
    "    states_xy = np.array(states_xy)\n",
    "    t = np.array(t)\n",
    "    \n",
    "    states_xy = states_xy[np.all(states_xy != 0,axis = 1)] #buang yg 0\n",
    "    states_xy = states_xy[np.all(~np.isnan(states_xy),axis = 1)] #buang yg nan\n",
    "    t = t[t != 0]\n",
    "\n",
    "    utm=[]\n",
    "    utm_baru=[]\n",
    "    t_utm = []\n",
    "\n",
    "    for topic, msg, time in bag.read_messages(topics=['/utm']):\n",
    "        utm.append([msg.pose.pose.position.x,msg.pose.pose.position.y])\n",
    "        t_utm.append(time.to_sec())\n",
    "\n",
    "    utm = np.array(utm)\n",
    "    t_utm = np.array(t_utm)\n",
    "    min = utm[0]\n",
    "\n",
    "    for i in range(len(states_xy)):\n",
    "        pass\n",
    "#         states_xy_baru.append([states_xy[i,0]-min[0],states_xy[i,1]-min[1]])\n",
    "    states_xy_baru = states_xy - min #vectorization\n",
    "    utm_baru = utm - min\n",
    "#     states_xy_baru=np.array(states_xy_baru)\n",
    "    \n",
    "    for i in range(len(utm)):\n",
    "        pass\n",
    "#         utm_baru.append([utm[i,0]-min[0],utm[i,1]-min[1]])\n",
    "\n",
    "    utm_baru=np.array(utm_baru)\n",
    "    return states_xy_baru, utm_baru, t, t_utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#function for plotting the estimation and the (unextended) GNSS points \n",
    "def plot(estimasi,gnss):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    matplotlib.style.use('default')\n",
    "\n",
    "    plt.scatter(estimasi[:,0],estimasi[:,1],s=2.,color='k') #odometry/filtered_map\n",
    "    plt.scatter(gnss[:,0],gnss[:,1],s=5.,marker=\"x\",c='C3',alpha=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function for saving the acquired parameter values to an external .txt file\n",
    "# def catat(p,q,error,fitness,p_path,q_path,error_path,error_bygen_path,\n",
    "#           fitness_path):\n",
    "def catat(p,q,error,fitness,path):\n",
    "    p = '%9.5g' * len(p) % tuple(p)\n",
    "    q = '%9.5g' * len(q) % tuple(q)\n",
    "    error = str(error)\n",
    "    fitness = str(fitness)\n",
    "\n",
    "    # adding new information to the temp files\n",
    "    with open(path['p'], 'a') as h:  \n",
    "        h.write(p + '\\n')\n",
    "    with open(path['q'], 'a') as h: \n",
    "        h.write(q + '\\n')\n",
    "    with open(path['error'], 'a') as h:  \n",
    "        h.write(error + '\\n')\n",
    "    with open(path['error_bygen'], 'a') as h:  \n",
    "        h.write(error + '\\n')\n",
    "    with open(path['fitness'], 'a') as h:  \n",
    "        h.write(fitness + '\\n')\n",
    "        \n",
    "    # loading the recently modified temp files nto numpy (for easier sort ith argsort)\n",
    "    x_q=np.loadtxt(path['q'], ndmin=2)  \n",
    "    x_p=np.loadtxt(path['p'], ndmin=2) \n",
    "    x_error=np.loadtxt(path['error'], ndmin=2)\n",
    "    x_fitness=np.loadtxt(path['fitness'], ndmin=2)\n",
    "    x_fitness_f=x_fitness.flatten()\n",
    "    \n",
    "    # saving and sorting by its corresponding fitness value\n",
    "    np.savetxt(path['p'], x_p[np.argsort(-x_fitness_f)], '%9.5g')\n",
    "    np.savetxt(path['q'], x_q[np.argsort(-x_fitness_f)], '%9.5g')\n",
    "    np.savetxt(path['error'], x_error[np.argsort(-x_fitness_f)], '%9.5g')\n",
    "    np.savetxt(path['fitness'], x_fitness[np.argsort(-x_fitness_f)], '%9.5g')  #[np.argsortnya ini nambah dimensi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all files in the path directory before launching\n",
    "def clear_path(folder):\n",
    "    os_folder = os.listdir(folder)\n",
    "    if os_folder:\n",
    "        for f in os_folder:\n",
    "            os.remove(os.path.join(folder, f))\n",
    "        print(\"Parameters' path is cleared!\")\n",
    "    else:\n",
    "        print(\"Parameters' path is already clear!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pq(p_diag, q_diag):\n",
    "    p, q = [[0,]*25]*2\n",
    "    for i,j in enumerate(range(0,25,6)):\n",
    "        p[j], q[j] = p_diag[i], q_diag[i]\n",
    "    return p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path(path,to_load):\n",
    "    vars = {}\n",
    "    for load in to_load:\n",
    "        vars[load] = np.loadtxt(path[load], ndmin=2)\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# initializing the parameter values\n",
    "p_diagonals = [10, 10, 10, 10, 1]\n",
    "q_diagonals = [10, 10, 10, 10, 1]\n",
    "p_temp, q_temp = init_pq(p_diagonals, q_diagonals)\n",
    "\n",
    "wd = os.getcwd() #the working directory (wd) and \n",
    "pwd = os.path.dirname(wd) #the parent of the wd (pwd)\n",
    "\n",
    "# define the max number of generations\n",
    "temp_folder = pwd + \"/logs/\"\n",
    "clear_path(temp_folder)\n",
    "\n",
    "params = ['p', 'q']\n",
    "errors_saved = ['error', 'error_bygen']\n",
    "temp_names = params + ['fitness'] + errors_saved\n",
    "to_load = params + ['fitness']\n",
    "\n",
    "# defining the filename for the values temps to be saved with\n",
    "path = {}\n",
    "for temp in temp_names:\n",
    "    path[temp] = temp_folder + temp + '_path.txt'\n",
    "\n",
    "generasi = 200\n",
    "for g in range(1, generasi+1):\n",
    "    print(\"----------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Generasi ke-\"+ str(g) + \" dari \" + str(generasi))\n",
    "\n",
    "    if os.path.exists(path['p']): # load the saved parameters after the 1st generation\n",
    "        # backbone of GA under here\n",
    "        var = load_from_path(path,to_load)\n",
    "        p,q,fitness = var['p'],var['q'],var['fitness']\n",
    "        #selection\n",
    "        n = min(25, len(p)) #defining the max number of the individuals in the population\n",
    "        \n",
    "        batas_bawah=1e-03\n",
    "#         daftar_parameter= [p[0],q[0]] #saving the (best?) parameters in p and q as an array\n",
    "        \n",
    "        #crossover (recombination of values)\n",
    "        if g > 2: #picking the parents for the crossover\n",
    "            indeks_ortu1,indeks_ortu2=random.sample(range(0, n), 2)\n",
    "            p_ortu=p[[indeks_ortu1,indeks_ortu2],:]\n",
    "            q_ortu=q[[indeks_ortu1,indeks_ortu2],:]\n",
    "            fitness_ortu=fitness[[indeks_ortu1,indeks_ortu2],:]\n",
    "            \n",
    "            w1=fitness_ortu[0]/(fitness_ortu[0]+fitness_ortu[1])\n",
    "            p, q = np.ones(25), np.ones(25)\n",
    "\n",
    "            for j in range(25):\n",
    "                pilih_ortu_p,pilih_ortu_q=np.random.random(),np.random.random()\n",
    "                p[j]=(pilih_ortu_p<=w1)*p_ortu[0,j]+(pilih_ortu_p>w1)*p_ortu[1,j]\n",
    "                q[j]=(pilih_ortu_q<=w1)*q_ortu[0,j]+(pilih_ortu_q>w1)*q_ortu[1,j]\n",
    "\n",
    "        #mutation\n",
    "        mp, s=0.8, 6 #mutation probability and the multiplying factor defined\n",
    "        if g < 25: #the initial population number defined here\n",
    "            mp,s=1,10 #for initial population, mutation is used to randomly pick the values around the inital values defines before\n",
    "        penjumlah=[]\n",
    "        \n",
    "        apakah_mutasi=np.random.random()\n",
    "        # condition of mutation existing\n",
    "        if apakah_mutasi<mp: \n",
    "            for a in range(10):\n",
    "                penjumlah.append((np.random.normal(0,1))) \n",
    "        # condition of mutation not existing\n",
    "        else:\n",
    "            penjumlah=np.zeros(10) #no addition for mutation\n",
    "        \n",
    "        m_p, m_q=np.zeros(25), np.zeros(25)\n",
    "\n",
    "        i=0\n",
    "        for b in range(0,25,6):\n",
    "            m_p[b]=penjumlah[i]\n",
    "            i+=1\n",
    "        for c in range(0,25,6):\n",
    "            m_q[c]=penjumlah[i]\n",
    "            i+=1\n",
    "            \n",
    "        p_temp = (p+m_p).flatten().tolist()\n",
    "        q_temp = (q+m_q).flatten().tolist()\n",
    "        \n",
    "        print(\"Matriks P generasi ke-\"+str(g+1)+\": \"+str(np.matrix(p_temp)))\n",
    "        for b in range(0,25,6):\n",
    "            if p_temp[b]<batas_bawah:\n",
    "                p_temp[b]=batas_bawah\n",
    "                \n",
    "        print(\"Matriks Q generasi ke-\"+str(g+1)+\": \"+str(np.matrix(q_temp)))\n",
    "        for c in range(0,25,6): #dibuat supaya q yaw tidak berubah\n",
    "            if q_temp[c]<batas_bawah:\n",
    "                q_temp[c]=batas_bawah\n",
    "            \n",
    "    #change the value of the parameter with the ones just acquired\n",
    "    params_yaml(p_temp,q_temp,pwd,temp)\n",
    "    p_sim,q_sim = p_temp,q_temp\n",
    "    #run the launch function\n",
    "    launch(pwd)\n",
    "    \n",
    "    # acquiring the fitness value by taking the estimation value from the temporary bag file (ga_temp.bag) and find the fitness from the error defined before\n",
    "    hasil_ukf, utm, t_state, t_utm = ambil_bag(pwd)\n",
    "\n",
    "    er_rmse, er_mae = err(hasil_ukf, utm, t_state, t_utm)\n",
    "    fit = 1/er_rmse\n",
    "    \n",
    "    #plot the estimation for every set of parameter values acquired\n",
    "    plot(hasil_ukf,utm)\n",
    "    \n",
    "    #saving the parameter values acquired\n",
    "    catat(p_temp,q_temp,er_rmse,fit,path)\n",
    "    \n",
    "var = load_from_path(path,params)\n",
    "p_best,q_best = var['p'][0].tolist(),var['q'][0].tolist()\n",
    "params_yaml(p_best,q_best,pwd) #only works with float, not numpy.float heh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
